/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * OpenAPI spec version: 2.0.0
 * 
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 * Do not edit the class manually.
 */
import { AssistantToolsCode } from './assistantToolsCode';
import { AssistantToolsFileSearch } from './assistantToolsFileSearch';
import { AssistantToolsFunction } from './assistantToolsFunction';
import { AssistantsApiResponseFormatOption } from './assistantsApiResponseFormatOption';
import { ModifyAssistantRequestToolResources } from './modifyAssistantRequestToolResources';

export interface ModifyAssistantRequest { 
    /**
     * ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them. 
     */
    model?: string;
    /**
     * The name of the assistant. The maximum length is 256 characters. 
     */
    name?: string;
    /**
     * The description of the assistant. The maximum length is 512 characters. 
     */
    description?: string;
    /**
     * The system instructions that the assistant uses. The maximum length is 256,000 characters. 
     */
    instructions?: string;
    /**
     * A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`. 
     */
    tools?: Array<AssistantToolsCode | AssistantToolsFileSearch | AssistantToolsFunction>;
    toolResources?: ModifyAssistantRequestToolResources;
    /**
     * Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long. 
     */
    metadata?: any;
    /**
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. 
     */
    temperature?: number;
    /**
     * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or temperature but not both. 
     */
    topP?: number;
    responseFormat?: AssistantsApiResponseFormatOption;
}