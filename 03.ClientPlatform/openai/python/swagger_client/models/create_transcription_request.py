# coding: utf-8

"""
    OpenAI API

    The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.  # noqa: E501

    OpenAPI spec version: 2.0.0
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

import pprint
import re  # noqa: F401

import six

class CreateTranscriptionRequest(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """
    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'file': 'str',
        'model': 'AnyOfCreateTranscriptionRequestModel',
        'language': 'str',
        'prompt': 'str',
        'response_format': 'str',
        'temperature': 'float',
        'timestamp_granularities': 'list[str]'
    }

    attribute_map = {
        'file': 'file',
        'model': 'model',
        'language': 'language',
        'prompt': 'prompt',
        'response_format': 'response_format',
        'temperature': 'temperature',
        'timestamp_granularities': 'timestamp_granularities[]'
    }

    def __init__(self, file=None, model=None, language=None, prompt=None, response_format='json', temperature=0, timestamp_granularities=None):  # noqa: E501
        """CreateTranscriptionRequest - a model defined in Swagger"""  # noqa: E501
        self._file = None
        self._model = None
        self._language = None
        self._prompt = None
        self._response_format = None
        self._temperature = None
        self._timestamp_granularities = None
        self.discriminator = None
        self.file = file
        self.model = model
        if language is not None:
            self.language = language
        if prompt is not None:
            self.prompt = prompt
        if response_format is not None:
            self.response_format = response_format
        if temperature is not None:
            self.temperature = temperature
        if timestamp_granularities is not None:
            self.timestamp_granularities = timestamp_granularities

    @property
    def file(self):
        """Gets the file of this CreateTranscriptionRequest.  # noqa: E501

        The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.   # noqa: E501

        :return: The file of this CreateTranscriptionRequest.  # noqa: E501
        :rtype: str
        """
        return self._file

    @file.setter
    def file(self, file):
        """Sets the file of this CreateTranscriptionRequest.

        The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.   # noqa: E501

        :param file: The file of this CreateTranscriptionRequest.  # noqa: E501
        :type: str
        """
        if file is None:
            raise ValueError("Invalid value for `file`, must not be `None`")  # noqa: E501

        self._file = file

    @property
    def model(self):
        """Gets the model of this CreateTranscriptionRequest.  # noqa: E501

        ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.   # noqa: E501

        :return: The model of this CreateTranscriptionRequest.  # noqa: E501
        :rtype: AnyOfCreateTranscriptionRequestModel
        """
        return self._model

    @model.setter
    def model(self, model):
        """Sets the model of this CreateTranscriptionRequest.

        ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.   # noqa: E501

        :param model: The model of this CreateTranscriptionRequest.  # noqa: E501
        :type: AnyOfCreateTranscriptionRequestModel
        """
        if model is None:
            raise ValueError("Invalid value for `model`, must not be `None`")  # noqa: E501

        self._model = model

    @property
    def language(self):
        """Gets the language of this CreateTranscriptionRequest.  # noqa: E501

        The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.   # noqa: E501

        :return: The language of this CreateTranscriptionRequest.  # noqa: E501
        :rtype: str
        """
        return self._language

    @language.setter
    def language(self, language):
        """Sets the language of this CreateTranscriptionRequest.

        The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.   # noqa: E501

        :param language: The language of this CreateTranscriptionRequest.  # noqa: E501
        :type: str
        """

        self._language = language

    @property
    def prompt(self):
        """Gets the prompt of this CreateTranscriptionRequest.  # noqa: E501

        An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.   # noqa: E501

        :return: The prompt of this CreateTranscriptionRequest.  # noqa: E501
        :rtype: str
        """
        return self._prompt

    @prompt.setter
    def prompt(self, prompt):
        """Sets the prompt of this CreateTranscriptionRequest.

        An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.   # noqa: E501

        :param prompt: The prompt of this CreateTranscriptionRequest.  # noqa: E501
        :type: str
        """

        self._prompt = prompt

    @property
    def response_format(self):
        """Gets the response_format of this CreateTranscriptionRequest.  # noqa: E501

        The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.   # noqa: E501

        :return: The response_format of this CreateTranscriptionRequest.  # noqa: E501
        :rtype: str
        """
        return self._response_format

    @response_format.setter
    def response_format(self, response_format):
        """Sets the response_format of this CreateTranscriptionRequest.

        The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.   # noqa: E501

        :param response_format: The response_format of this CreateTranscriptionRequest.  # noqa: E501
        :type: str
        """
        allowed_values = ["json", "text", "srt", "verbose_json", "vtt"]  # noqa: E501
        if response_format not in allowed_values:
            raise ValueError(
                "Invalid value for `response_format` ({0}), must be one of {1}"  # noqa: E501
                .format(response_format, allowed_values)
            )

        self._response_format = response_format

    @property
    def temperature(self):
        """Gets the temperature of this CreateTranscriptionRequest.  # noqa: E501

        The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.   # noqa: E501

        :return: The temperature of this CreateTranscriptionRequest.  # noqa: E501
        :rtype: float
        """
        return self._temperature

    @temperature.setter
    def temperature(self, temperature):
        """Sets the temperature of this CreateTranscriptionRequest.

        The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.   # noqa: E501

        :param temperature: The temperature of this CreateTranscriptionRequest.  # noqa: E501
        :type: float
        """

        self._temperature = temperature

    @property
    def timestamp_granularities(self):
        """Gets the timestamp_granularities of this CreateTranscriptionRequest.  # noqa: E501

        The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.   # noqa: E501

        :return: The timestamp_granularities of this CreateTranscriptionRequest.  # noqa: E501
        :rtype: list[str]
        """
        return self._timestamp_granularities

    @timestamp_granularities.setter
    def timestamp_granularities(self, timestamp_granularities):
        """Sets the timestamp_granularities of this CreateTranscriptionRequest.

        The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.   # noqa: E501

        :param timestamp_granularities: The timestamp_granularities of this CreateTranscriptionRequest.  # noqa: E501
        :type: list[str]
        """
        allowed_values = ["word", "segment"]  # noqa: E501
        if not set(timestamp_granularities).issubset(set(allowed_values)):
            raise ValueError(
                "Invalid values for `timestamp_granularities` [{0}], must be a subset of [{1}]"  # noqa: E501
                .format(", ".join(map(str, set(timestamp_granularities) - set(allowed_values))),  # noqa: E501
                        ", ".join(map(str, allowed_values)))
            )

        self._timestamp_granularities = timestamp_granularities

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value
        if issubclass(CreateTranscriptionRequest, dict):
            for key, value in self.items():
                result[key] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, CreateTranscriptionRequest):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
